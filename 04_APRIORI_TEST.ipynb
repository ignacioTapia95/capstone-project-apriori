{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de8cd4b4-97f6-458e-a9ed-94afb452dc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerías principales\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "import random\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "# Librerías Proyecto\n",
    "from lib.RecSysClusters import ClusterRFM\n",
    "from lib.RecSys import AprioriSys\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b35a861-57b6-420c-ba93-009b07f1f192",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clusters = pd.read_csv('../data/data_rfm.csv', header=0)[['usuario_id_crp', 'year_month','freq_all_1', 'mon_all_1']]\n",
    "df_recsys = pd.read_csv('../data/data_trx.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bde40c84-2dcf-4e74-8059-f1032a0d0672",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_json('../data/df_dummy_leave_one.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f48eef2-b64c-4c6b-b8b3-ccac4ed71f07",
   "metadata": {},
   "source": [
    "## GRID SHEARCH: ARIORI CONTRA BENCHMARKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "367a26fe-fb9d-45d2-8788-2151d99aaf84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50368it [24:46, 33.89it/s]\n",
      "6036it [02:09, 46.58it/s]\n",
      "7338it [03:29, 34.96it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 98>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     89\u001b[0m     list_results\u001b[38;5;241m.\u001b[39mappend(resultados)\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m#Generar el dataframe de los ejecrcicios\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m#df = pd.DataFrame()\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m#for i in list_results:\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m#    df = df.append(pd.DataFrame(i), ignore_index=True)\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m#Exportar resultados en parquet\u001b[39;00m\n\u001b[0;32m---> 98\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./resultados/apriori_con_cluster.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "random.seed(20220720)\n",
    "\n",
    "list_results = []\n",
    "top_n_clusters = []\n",
    "\n",
    "\n",
    "# Definir DataFrames\n",
    "df_cluster_train = df_clusters[df_clusters['year_month'] < '2022-01-01'].reset_index(drop=True)\n",
    "df_cluster_test = df_clusters[df_clusters['year_month'] >= '2022-01-01'].reset_index(drop=True)\n",
    "df_recsys_train = df_recsys[df_recsys['fecha'] < '2022-01-01'].reset_index(drop=True)\n",
    "df_recsys_test = df_test[df_test['fecha'] >= '2022-01-01'].reset_index(drop=True)\n",
    "\n",
    "#Definir Subcategorias\n",
    "subcategorias = list(df_recsys_train['subcat_comercial'].unique())\n",
    "\n",
    "# Definir Clusters de Entrenamiento\n",
    "cluster = ClusterRFM(df=df_cluster_train, user_id='usuario_id_crp', frequency_column='freq_all_1', monetary_column='mon_all_1', n_clusters=3)\n",
    "cluster_cliente_entrenamiento = cluster.cluster_customer()\n",
    "\n",
    "# Predecir Clusters de Test\n",
    "cluster_test = ClusterRFM(df=df_cluster_test, user_id='usuario_id_crp', frequency_column='freq_all_1', monetary_column='mon_all_1', n_clusters=3, trained_model=cluster.trained_model, trained_scaled_model=cluster.scaler)\n",
    "cluster_cliente_test = cluster_test.cluster_customer()\n",
    "\n",
    "# Asoignar cluster a cada cliente\n",
    "df_recsys_train['cluster'] = df_recsys_train['usuario_id_crp'].map(cluster_cliente_entrenamiento)\n",
    "df_recsys_test['cluster'] = df_recsys_test['usuarioidcrp'].map(cluster_cliente_test)\n",
    "\n",
    "# Definir dataframes por cluster\n",
    "set_df_recsys_train = {}\n",
    "set_df_recsys_test = {}\n",
    "set_top_n_train = {}\n",
    "listas_top_n_train = {}\n",
    "for n_cluster in range(cluster.n_clusters):\n",
    "    set_df_recsys_train[f'cluster_{n_cluster}'] = df_recsys_train[df_recsys_train['cluster'] == n_cluster].drop(columns='cluster',axis=1).reset_index(drop=True)\n",
    "    set_df_recsys_test[f'cluster_{n_cluster}'] = df_recsys_test[df_recsys_test['cluster'] == n_cluster].drop(columns='cluster',axis=1).set_index('ventaidcrp')\n",
    "\n",
    "    # Obtener lista de productos populares (top) del cluster y almacenar\n",
    "    df_top_n = set_df_recsys_train[f'cluster_{n_cluster}'].reset_index(drop=True)\n",
    "    df_top_n = df_top_n.groupby('subcat_comercial').count().sort_values('venta_id_crp', ascending=False)\n",
    "    top = list(df_top_n.index)\n",
    "    listas_top_n_train[n_cluster] = top\n",
    "\n",
    "\n",
    "# Ejecutar Ejercicio por Cluster\n",
    "cluster_rules = {}\n",
    "for n_cluster in range(cluster.n_clusters):\n",
    "\n",
    "    # Ajustar algoritmo apriori\n",
    "    apriori_sys = AprioriSys(df=set_df_recsys_train[f'cluster_{n_cluster}'], porduct_column='subcat_comercial', min_support=0.001)\n",
    "    cluster_rules[f'reglas_cluster_{n_cluster}'] = apriori_sys.fit_rules()\n",
    "\n",
    "    # Predecir\n",
    "    resultados={\n",
    "        'venta_id_crp':[],\n",
    "        'cluster':[],\n",
    "        'apriori_metric':[],\n",
    "        'n_recommendations':[],\n",
    "        'rec_apriori':[],\n",
    "        'rec_random':[],\n",
    "        'rec_top_subcat':[]\n",
    "    }\n",
    "\n",
    "    # Iterar por el dataframe del cluster\n",
    "    for index,row in tqdm(set_df_recsys_test[f'cluster_{n_cluster}'].iterrows()):\n",
    "\n",
    "        # Iterar por función a maximizar\n",
    "        for metric in ['confidence', 'lift']:\n",
    "\n",
    "            # Iterar por cantidad de productos recomendados\n",
    "            for n_rec in [1,2,3]:\n",
    "\n",
    "                # Obtener Recomendaciones de los modelos benchmark\n",
    "                rec_random = random.sample(subcategorias,n_rec)\n",
    "                top_n = listas_top_n_train[n_cluster][:n_rec]\n",
    "\n",
    "                # Obtener Recomendaciones del modelo apriori\n",
    "                recomendacion_apriori = apriori_sys.predict(basket=pd.DataFrame(row[2:]).T, metric=metric, n_recommendations=n_rec)\n",
    "\n",
    "                # Almacenar Resultados Especificos\n",
    "                resultados['venta_id_crp'].append(index)\n",
    "                resultados['cluster'].append(n_cluster)\n",
    "                resultados['apriori_metric'].append(metric)\n",
    "                resultados['n_recommendations'].append(n_rec)\n",
    "                resultados['rec_apriori'].append(recomendacion_apriori)\n",
    "                resultados['rec_random'].append(rec_random)\n",
    "                resultados['rec_top_subcat'].append(top_n)\n",
    "\n",
    "    # Almacenar Resultados Generales\n",
    "    list_results.append(resultados)\n",
    "\n",
    "\n",
    "#Generar el dataframe de los ejecrcicios\n",
    "#df = pd.DataFrame()\n",
    "#for i in list_results:\n",
    "#    df = df.append(pd.DataFrame(i), ignore_index=True)\n",
    "\n",
    "#Exportar resultados en parquet\n",
    "df.to_csv('./resultados/apriori_con_cluster.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca0c7c56-ff32-4a0c-9e34-8808fbd552ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for i in list_results:\n",
    "    df = df.append(pd.DataFrame(i), ignore_index=True)\n",
    "\n",
    "leave_one = pd.read_csv('../data/leave_one.csv')\n",
    "df = df.merge(leave_one, on='venta_id_crp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eff9b373-3fc5-48d0-9972-180b58dd2b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hit_apriori'] = df.apply(lambda x: 1 if x['leave_one'] in x['rec_apriori'] else 0, axis=1)\n",
    "df['hit_random'] = df.apply(lambda x: 1 if x['leave_one'] in x['rec_random'] else 0, axis=1)\n",
    "df['hit_top'] = df.apply(lambda x: 1 if x['leave_one'] in x['rec_top_subcat'] else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b8874da-7fcc-46c8-b172-f70cfb1a62d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./resultados/apriori_con_cluster.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c5e41c1a-c9b7-47a3-9520-5a0a98370740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>hit_apriori</th>\n",
       "      <th>hit_random</th>\n",
       "      <th>hit_top</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apriori_metric</th>\n",
       "      <th>n_recommendations</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">confidence</th>\n",
       "      <th>1</th>\n",
       "      <td>0.265555</td>\n",
       "      <td>0.014794</td>\n",
       "      <td>0.108374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.391375</td>\n",
       "      <td>0.029353</td>\n",
       "      <td>0.253444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.456904</td>\n",
       "      <td>0.044743</td>\n",
       "      <td>0.315412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">lift</th>\n",
       "      <th>1</th>\n",
       "      <td>0.260174</td>\n",
       "      <td>0.014574</td>\n",
       "      <td>0.108374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.335226</td>\n",
       "      <td>0.030608</td>\n",
       "      <td>0.253444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.393838</td>\n",
       "      <td>0.044147</td>\n",
       "      <td>0.315412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  hit_apriori  hit_random   hit_top\n",
       "apriori_metric n_recommendations                                   \n",
       "confidence     1                     0.265555    0.014794  0.108374\n",
       "               2                     0.391375    0.029353  0.253444\n",
       "               3                     0.456904    0.044743  0.315412\n",
       "lift           1                     0.260174    0.014574  0.108374\n",
       "               2                     0.335226    0.030608  0.253444\n",
       "               3                     0.393838    0.044147  0.315412"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['apriori_metric', 'n_recommendations'])[['hit_apriori', 'hit_random', 'hit_top']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96264396-ec4c-4621-bb62-2b673fe98b65",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rolling False\n",
      "2020-03-01 2021-03-01 2021-04-01 2021-05-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7016it [10:19, 11.32it/s]\n",
      "3095it [04:53, 10.53it/s]\n",
      "1589it [01:50, 14.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-01 2021-04-01 2021-05-01 2021-06-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2843it [04:35, 10.32it/s]\n",
      "1485it [01:43, 14.28it/s]\n",
      "6277it [09:11, 11.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-01 2021-05-01 2021-06-01 2021-07-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2801it [04:23, 10.65it/s]\n",
      "1553it [01:47, 14.44it/s]\n",
      "6243it [09:06, 11.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-01 2021-06-01 2021-07-01 2021-08-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5542it [08:13, 11.24it/s]\n",
      "1182it [01:22, 14.40it/s]\n",
      "2668it [04:00, 11.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-01 2021-07-01 2021-08-01 2021-09-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5364it [07:52, 11.35it/s]\n",
      "1415it [01:37, 14.44it/s]\n",
      "2772it [04:16, 10.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-01 2021-08-01 2021-09-01 2021-10-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1066it [01:12, 14.74it/s]\n",
      "2840it [04:16, 11.05it/s]\n",
      "5218it [07:36, 11.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-01 2021-09-01 2021-10-01 2021-11-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4175it [06:07, 11.36it/s]\n",
      "2463it [03:38, 11.25it/s]\n",
      "732it [00:49, 14.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-01 2021-10-01 2021-11-01 2021-12-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "799it [00:54, 14.60it/s]\n",
      "2347it [03:27, 11.30it/s]\n",
      "3706it [05:15, 11.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-01 2021-11-01 2021-12-01 2022-01-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5028it [07:10, 11.68it/s]\n",
      "1281it [01:27, 14.72it/s]\n",
      "2749it [04:19, 10.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-01 2021-12-01 2022-01-01 2022-02-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2034it [02:58, 11.38it/s]\n",
      "3725it [05:17, 11.72it/s]\n",
      "1256it [01:27, 14.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-01 2022-01-01 2022-02-01 2022-03-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3939it [05:41, 11.55it/s]\n",
      "2331it [03:23, 11.48it/s]\n",
      "1421it [01:37, 14.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-01 2022-02-01 2022-03-01 2022-04-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2538it [03:49, 11.04it/s]\n",
      "1959it [02:13, 14.62it/s]\n",
      "4531it [06:24, 11.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-01 2022-03-01 2022-04-01 2022-05-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3308it [04:44, 11.63it/s]\n",
      "1906it [02:10, 14.65it/s]\n",
      "6023it [08:31, 11.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-01 2022-04-01 2022-05-01 2022-06-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7005it [09:54, 11.79it/s]\n",
      "2018it [02:17, 14.63it/s]\n",
      "2983it [04:20, 11.47it/s]\n"
     ]
    }
   ],
   "source": [
    "random.seed(20220720)\n",
    "\n",
    "list_results = []\n",
    "top_n_clusters = []\n",
    "\n",
    "for rolling in [False]:\n",
    "    \n",
    "    start_date = date(2020,3,1)\n",
    "    max_date =  date(2022,6,1)\n",
    "    minimum_windows_size = 12\n",
    "    \n",
    "    print(f'rolling {rolling}')\n",
    "    \n",
    "    start_train = start_date\n",
    "    end_train = start_train + relativedelta(months=minimum_windows_size)\n",
    "    start_test = start_train + relativedelta(months=minimum_windows_size+1)\n",
    "    end_test = start_test + relativedelta(months=1)\n",
    "\n",
    "    while start_test <= max_date:\n",
    "\n",
    "        print(start_train, end_train, start_test, end_test)\n",
    "\n",
    "        # Definir DataFrames\n",
    "        df_cluster_train = df_clusters[(df_clusters['year_month'] >= start_train.strftime('%Y-%m-%d')) & (df_clusters['year_month'] <= end_train.strftime('%Y-%m-%d'))].reset_index(drop=True)\n",
    "        df_cluster_test = df_clusters[(df_clusters['year_month'] >= (end_train + relativedelta(months=1)).strftime('%Y-%m-%d')) & (df_clusters['year_month'] < (end_train + relativedelta(months=2)).strftime('%Y-%m-%d'))].reset_index(drop=True)\n",
    "        df_recsys_train = df_recsys[(df_recsys['fecha'] >= start_train.strftime('%Y-%m-%d')) & (df_recsys['fecha'] <= end_train.strftime('%Y-%m-%d'))].reset_index(drop=True)\n",
    "        df_recsys_test = df_test[(df_test['fecha'] >= start_test.strftime('%Y-%m-%d')) & (df_test['fecha'] < end_test.strftime('%Y-%m-%d'))].reset_index(drop=True)\n",
    "        \n",
    "        #Definir Subcategorias\n",
    "        subcategorias = list(df_recsys_train['subcat_comercial'].unique())\n",
    "                \n",
    "        # Definir Clusters de Entrenamiento\n",
    "        cluster = ClusterRFM(df=df_cluster_train, user_id='usuario_id_crp', frequency_column='freq_all_1', monetary_column='mon_all_1', n_clusters=3)\n",
    "        cluster_cliente_entrenamiento = cluster.cluster_customer()\n",
    "\n",
    "        # Predecir Clusters de Test\n",
    "        cluster_test = ClusterRFM(df=df_cluster_test, user_id='usuario_id_crp', frequency_column='freq_all_1', monetary_column='mon_all_1', n_clusters=3, trained_model=cluster.trained_model, trained_scaled_model=cluster.scaler)\n",
    "        cluster_cliente_test = cluster_test.cluster_customer()\n",
    "\n",
    "        # Asoignar cluster a cada cliente\n",
    "        df_recsys_train['cluster'] = df_recsys_train['usuario_id_crp'].map(cluster_cliente_entrenamiento)\n",
    "        df_recsys_test['cluster'] = df_recsys_test['usuarioidcrp'].map(cluster_cliente_test)\n",
    "        \n",
    "        # Definir dataframes por cluster\n",
    "        set_df_recsys_train = {}\n",
    "        set_df_recsys_test = {}\n",
    "        set_top_n_train = {}\n",
    "        listas_top_n_train = {}\n",
    "        for n_cluster in range(cluster.n_clusters):\n",
    "            set_df_recsys_train[f'cluster_{n_cluster}'] = df_recsys_train[df_recsys_train['cluster'] == n_cluster].drop(columns='cluster',axis=1).reset_index(drop=True)\n",
    "            set_df_recsys_test[f'cluster_{n_cluster}'] = df_recsys_test[df_recsys_test['cluster'] == n_cluster].drop(columns='cluster',axis=1).set_index('ventaidcrp')\n",
    "            \n",
    "            # Obtener lista de productos populares (top) del cluster y almacenar\n",
    "            df_top_n = set_df_recsys_train[f'cluster_{n_cluster}'].reset_index(drop=True)\n",
    "            df_top_n = df_top_n.groupby('subcat_comercial').count().sort_values('venta_id_crp', ascending=False)\n",
    "            top = list(df_top_n.index)\n",
    "            listas_top_n_train[n_cluster] = top\n",
    "            \n",
    "            \n",
    "        # Ejecutar Ejercicio por Cluster\n",
    "        cluster_rules = {}\n",
    "        for n_cluster in range(cluster.n_clusters):\n",
    "            \n",
    "            # Ajustar algoritmo apriori\n",
    "            apriori_sys = AprioriSys(df=set_df_recsys_train[f'cluster_{n_cluster}'], porduct_column='subcat_comercial', min_support=0.001)\n",
    "            cluster_rules[f'reglas_cluster_{n_cluster}'] = apriori_sys.fit_rules()\n",
    "            \n",
    "            # Predecir\n",
    "            resultados={\n",
    "                'rolling':[],\n",
    "                'start_train':[],\n",
    "                'end_train':[],\n",
    "                'start_test':[],\n",
    "                'end_test':[],\n",
    "                'venta_id_crp':[],\n",
    "                'cluster':[],\n",
    "                'apriori_metric':[],\n",
    "                'n_recommendations':[],\n",
    "                'rec_apriori':[],\n",
    "                'rec_random':[],\n",
    "                'rec_top_subcat':[]\n",
    "            }\n",
    "            \n",
    "            # Iterar por el dataframe del cluster\n",
    "            for index,row in tqdm(set_df_recsys_test[f'cluster_{n_cluster}'].iterrows()):\n",
    "                \n",
    "                # Iterar por función a maximizar\n",
    "                for metric in ['consequent support', 'confidence', 'lift', 'leverage', 'conviction']:\n",
    "                    \n",
    "                    # Iterar por cantidad de productos recomendados\n",
    "                    for n_rec in [1,2,3]:\n",
    "                        \n",
    "                        # Obtener Recomendaciones de los modelos benchmark\n",
    "                        rec_random = random.sample(subcategorias,n_rec)\n",
    "                        top_n = listas_top_n_train[n_cluster][:n_rec]\n",
    "                        \n",
    "                        # Obtener Recomendaciones del modelo apriori\n",
    "                        recomendacion_apriori = apriori_sys.predict(basket=pd.DataFrame(row[2:]).T, metric=metric, n_recommendations=n_rec)\n",
    "                        \n",
    "                        # Almacenar Resultados Especificos\n",
    "                        resultados['rolling'].append(rolling)\n",
    "                        resultados['start_train'].append(start_train)\n",
    "                        resultados['end_train'].append(end_train)\n",
    "                        resultados['start_test'].append(start_test)\n",
    "                        resultados['end_test'].append(end_test)\n",
    "                        resultados['venta_id_crp'].append(index)\n",
    "                        resultados['cluster'].append(n_cluster)\n",
    "                        resultados['apriori_metric'].append(metric)\n",
    "                        resultados['n_recommendations'].append(n_rec)\n",
    "                        resultados['rec_apriori'].append(recomendacion_apriori)\n",
    "                        resultados['rec_random'].append(rec_random)\n",
    "                        resultados['rec_top_subcat'].append(top_n)\n",
    "            \n",
    "            # Almacenar Resultados Generales\n",
    "            list_results.append(resultados)\n",
    "\n",
    "        # Actualizar Fechas\n",
    "        if rolling == True:\n",
    "            start_train += relativedelta(months=1)\n",
    "\n",
    "        end_train += relativedelta(months=1)\n",
    "        start_test += relativedelta(months=1)\n",
    "        end_test += relativedelta(months=1)\n",
    "        \n",
    "\n",
    "#Generar el dataframe de los ejecrcicios\n",
    "df = pd.DataFrame()\n",
    "for i in list_results:\n",
    "    df = df.append(pd.DataFrame(i), ignore_index=True)\n",
    "\n",
    "#Exportar resultados en parquet\n",
    "df.to_csv('./resultados/recursive_v2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c5554a-f5c6-45cb-8614-2aef13e7f931",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Pruebas Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "baa22e26-2a8a-417a-a4ec-4c87651fb0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparacion = pd.read_json('../data/dataset_test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fa7e383a-3114-4037-89b4-aaddb888b2b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fecha</th>\n",
       "      <th>venta_id_crp</th>\n",
       "      <th>usuario_id_crp</th>\n",
       "      <th>canasta_original</th>\n",
       "      <th>canasta_test</th>\n",
       "      <th>leave_one</th>\n",
       "      <th>recomendacion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-04-01</td>\n",
       "      <td>428056</td>\n",
       "      <td>1925806</td>\n",
       "      <td>[POSTRE INDIVIDUAL, SANDWICH, JUGO]</td>\n",
       "      <td>[POSTRE INDIVIDUAL, SANDWICH]</td>\n",
       "      <td>JUGO</td>\n",
       "      <td>[BARQUILLO, EMPANADA INDIVIDUAL, EMPANADITA, G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-04-01</td>\n",
       "      <td>428057</td>\n",
       "      <td>771075</td>\n",
       "      <td>[EMPANADITA, BARQUILLO, PANADERIA, MAP, ALFAJOR]</td>\n",
       "      <td>[EMPANADITA, BARQUILLO, ALFAJOR, PANADERIA]</td>\n",
       "      <td>MAP</td>\n",
       "      <td>[BOLLERIA, CALUGA, FRUTOS SECOS, MAP, POSTRE I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-04-01</td>\n",
       "      <td>428058</td>\n",
       "      <td>1853170</td>\n",
       "      <td>[EMPANADITA, POSTRE FAMILIAR]</td>\n",
       "      <td>[POSTRE FAMILIAR]</td>\n",
       "      <td>EMPANADITA</td>\n",
       "      <td>[COCKTAIL CONGELADO, LASAÑA, MAP FAMILIAR, PAN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-04-01</td>\n",
       "      <td>428060</td>\n",
       "      <td>1916418</td>\n",
       "      <td>[POSTRE INDIVIDUAL, PLATO LIVIANO, PANADERIA]</td>\n",
       "      <td>[POSTRE INDIVIDUAL, PLATO LIVIANO]</td>\n",
       "      <td>PANADERIA</td>\n",
       "      <td>[EMPANADA INDIVIDUAL, EMPANADITA, ENSALADA, GA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-04-01</td>\n",
       "      <td>428068</td>\n",
       "      <td>526798</td>\n",
       "      <td>[EMPANADITA, PIZZA, PANADERIA]</td>\n",
       "      <td>[EMPANADITA, PIZZA]</td>\n",
       "      <td>PANADERIA</td>\n",
       "      <td>[BOLLERIA, EMPANADA INDIVIDUAL, PANADERIA, POS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7011</th>\n",
       "      <td>2021-04-30</td>\n",
       "      <td>457941</td>\n",
       "      <td>1396669</td>\n",
       "      <td>[JUGO, QUESO LAMINADO, PANADERIA]</td>\n",
       "      <td>[QUESO LAMINADO, PANADERIA]</td>\n",
       "      <td>JUGO</td>\n",
       "      <td>[ALFAJOR, BOLLERIA, DIP, FRUTOS SECOS, JAMON, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7012</th>\n",
       "      <td>2021-04-30</td>\n",
       "      <td>457948</td>\n",
       "      <td>677920</td>\n",
       "      <td>[GALLETA DULCE, ALFAJOR, EMPANADA INDIVIDUAL, ...</td>\n",
       "      <td>[ALFAJOR, EMPANADA INDIVIDUAL, FRUTOS SECOS]</td>\n",
       "      <td>GALLETA DULCE</td>\n",
       "      <td>[BARQUILLO, BOLLERIA, CALUGA, GALLETA SALADA, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7013</th>\n",
       "      <td>2021-04-30</td>\n",
       "      <td>457953</td>\n",
       "      <td>1528614</td>\n",
       "      <td>[PANADERIA, SALAME, QUESO LAMINADO]</td>\n",
       "      <td>[SALAME, PANADERIA]</td>\n",
       "      <td>QUESO LAMINADO</td>\n",
       "      <td>[BOLLERIA, FRUTOS SECOS, JAMON, QUESO LAMINADO]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7014</th>\n",
       "      <td>2021-04-30</td>\n",
       "      <td>457961</td>\n",
       "      <td>1477438</td>\n",
       "      <td>[PANADERIA, GALLETA SALADA, MANTEQUILLA]</td>\n",
       "      <td>[MANTEQUILLA, PANADERIA]</td>\n",
       "      <td>GALLETA SALADA</td>\n",
       "      <td>[BOLLERIA, JAMON, POSTRE INDIVIDUAL, QUESO LAM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7015</th>\n",
       "      <td>2021-04-30</td>\n",
       "      <td>457970</td>\n",
       "      <td>734552</td>\n",
       "      <td>[JAMON, BOLLERIA, EMPANADA INDIVIDUAL, PANADERIA]</td>\n",
       "      <td>[JAMON, EMPANADA INDIVIDUAL, PANADERIA]</td>\n",
       "      <td>BOLLERIA</td>\n",
       "      <td>[BOLLERIA, POSTRE INDIVIDUAL, QUESO, QUESO LAM...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7016 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           fecha  venta_id_crp  usuario_id_crp  \\\n",
       "0     2021-04-01        428056         1925806   \n",
       "1     2021-04-01        428057          771075   \n",
       "2     2021-04-01        428058         1853170   \n",
       "3     2021-04-01        428060         1916418   \n",
       "4     2021-04-01        428068          526798   \n",
       "...          ...           ...             ...   \n",
       "7011  2021-04-30        457941         1396669   \n",
       "7012  2021-04-30        457948          677920   \n",
       "7013  2021-04-30        457953         1528614   \n",
       "7014  2021-04-30        457961         1477438   \n",
       "7015  2021-04-30        457970          734552   \n",
       "\n",
       "                                       canasta_original  \\\n",
       "0                   [POSTRE INDIVIDUAL, SANDWICH, JUGO]   \n",
       "1      [EMPANADITA, BARQUILLO, PANADERIA, MAP, ALFAJOR]   \n",
       "2                         [EMPANADITA, POSTRE FAMILIAR]   \n",
       "3         [POSTRE INDIVIDUAL, PLATO LIVIANO, PANADERIA]   \n",
       "4                        [EMPANADITA, PIZZA, PANADERIA]   \n",
       "...                                                 ...   \n",
       "7011                  [JUGO, QUESO LAMINADO, PANADERIA]   \n",
       "7012  [GALLETA DULCE, ALFAJOR, EMPANADA INDIVIDUAL, ...   \n",
       "7013                [PANADERIA, SALAME, QUESO LAMINADO]   \n",
       "7014           [PANADERIA, GALLETA SALADA, MANTEQUILLA]   \n",
       "7015  [JAMON, BOLLERIA, EMPANADA INDIVIDUAL, PANADERIA]   \n",
       "\n",
       "                                      canasta_test       leave_one  \\\n",
       "0                    [POSTRE INDIVIDUAL, SANDWICH]            JUGO   \n",
       "1      [EMPANADITA, BARQUILLO, ALFAJOR, PANADERIA]             MAP   \n",
       "2                                [POSTRE FAMILIAR]      EMPANADITA   \n",
       "3               [POSTRE INDIVIDUAL, PLATO LIVIANO]       PANADERIA   \n",
       "4                              [EMPANADITA, PIZZA]       PANADERIA   \n",
       "...                                            ...             ...   \n",
       "7011                   [QUESO LAMINADO, PANADERIA]            JUGO   \n",
       "7012  [ALFAJOR, EMPANADA INDIVIDUAL, FRUTOS SECOS]   GALLETA DULCE   \n",
       "7013                           [SALAME, PANADERIA]  QUESO LAMINADO   \n",
       "7014                      [MANTEQUILLA, PANADERIA]  GALLETA SALADA   \n",
       "7015       [JAMON, EMPANADA INDIVIDUAL, PANADERIA]        BOLLERIA   \n",
       "\n",
       "                                          recomendacion  \n",
       "0     [BARQUILLO, EMPANADA INDIVIDUAL, EMPANADITA, G...  \n",
       "1     [BOLLERIA, CALUGA, FRUTOS SECOS, MAP, POSTRE I...  \n",
       "2     [COCKTAIL CONGELADO, LASAÑA, MAP FAMILIAR, PAN...  \n",
       "3     [EMPANADA INDIVIDUAL, EMPANADITA, ENSALADA, GA...  \n",
       "4     [BOLLERIA, EMPANADA INDIVIDUAL, PANADERIA, POS...  \n",
       "...                                                 ...  \n",
       "7011  [ALFAJOR, BOLLERIA, DIP, FRUTOS SECOS, JAMON, ...  \n",
       "7012  [BARQUILLO, BOLLERIA, CALUGA, GALLETA SALADA, ...  \n",
       "7013    [BOLLERIA, FRUTOS SECOS, JAMON, QUESO LAMINADO]  \n",
       "7014  [BOLLERIA, JAMON, POSTRE INDIVIDUAL, QUESO LAM...  \n",
       "7015  [BOLLERIA, POSTRE INDIVIDUAL, QUESO, QUESO LAM...  \n",
       "\n",
       "[7016 rows x 7 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparacion_2 = comparacion.merge(resultados_2, how='inner', on='venta_id_crp')\n",
    "comparacion_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a22076c0-cd70-4034-be87-660666aa0f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7016it [00:00, 23149.25it/s]\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "for index,row in tqdm(comparacion_2.iterrows()):\n",
    "   \n",
    "    res.append(row['leave_one'] in row['recomendacion'])\n",
    "\n",
    "comparacion_2['hit'] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2b6e4ea7-5e39-477b-b835-85cba7e7abee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4605188141391106"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(res) / comparacion_2.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7a698dd6-a314-4d0b-a94d-ed003e1a225c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4484036488027366"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(res) / comparacion_2.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b1ea0de4-e003-43dc-9484-1352b330615a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3983751425313569"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(res) / comparacion_2.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6709d608-986c-4b4b-af17-b1d4322b1cb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fecha</th>\n",
       "      <th>venta_id_crp</th>\n",
       "      <th>usuario_id_crp</th>\n",
       "      <th>canasta_original</th>\n",
       "      <th>canasta_test</th>\n",
       "      <th>leave_one</th>\n",
       "      <th>recomendacion</th>\n",
       "      <th>hit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-04-01</td>\n",
       "      <td>428056</td>\n",
       "      <td>1925806</td>\n",
       "      <td>[POSTRE INDIVIDUAL, SANDWICH, JUGO]</td>\n",
       "      <td>[POSTRE INDIVIDUAL, SANDWICH]</td>\n",
       "      <td>JUGO</td>\n",
       "      <td>[BARQUILLO, EMPANADA INDIVIDUAL, EMPANADITA, G...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-04-01</td>\n",
       "      <td>428057</td>\n",
       "      <td>771075</td>\n",
       "      <td>[EMPANADITA, BARQUILLO, PANADERIA, MAP, ALFAJOR]</td>\n",
       "      <td>[EMPANADITA, BARQUILLO, ALFAJOR, PANADERIA]</td>\n",
       "      <td>MAP</td>\n",
       "      <td>[BOLLERIA, CALUGA, FRUTOS SECOS, MAP, POSTRE I...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-04-01</td>\n",
       "      <td>428058</td>\n",
       "      <td>1853170</td>\n",
       "      <td>[EMPANADITA, POSTRE FAMILIAR]</td>\n",
       "      <td>[POSTRE FAMILIAR]</td>\n",
       "      <td>EMPANADITA</td>\n",
       "      <td>[COCKTAIL CONGELADO, LASAÑA, MAP FAMILIAR, PAN...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-04-01</td>\n",
       "      <td>428060</td>\n",
       "      <td>1916418</td>\n",
       "      <td>[POSTRE INDIVIDUAL, PLATO LIVIANO, PANADERIA]</td>\n",
       "      <td>[POSTRE INDIVIDUAL, PLATO LIVIANO]</td>\n",
       "      <td>PANADERIA</td>\n",
       "      <td>[EMPANADA INDIVIDUAL, EMPANADITA, ENSALADA, GA...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-04-01</td>\n",
       "      <td>428068</td>\n",
       "      <td>526798</td>\n",
       "      <td>[EMPANADITA, PIZZA, PANADERIA]</td>\n",
       "      <td>[EMPANADITA, PIZZA]</td>\n",
       "      <td>PANADERIA</td>\n",
       "      <td>[BOLLERIA, EMPANADA INDIVIDUAL, PANADERIA, POS...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7011</th>\n",
       "      <td>2021-04-30</td>\n",
       "      <td>457941</td>\n",
       "      <td>1396669</td>\n",
       "      <td>[JUGO, QUESO LAMINADO, PANADERIA]</td>\n",
       "      <td>[QUESO LAMINADO, PANADERIA]</td>\n",
       "      <td>JUGO</td>\n",
       "      <td>[ALFAJOR, BOLLERIA, DIP, FRUTOS SECOS, JAMON, ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7012</th>\n",
       "      <td>2021-04-30</td>\n",
       "      <td>457948</td>\n",
       "      <td>677920</td>\n",
       "      <td>[GALLETA DULCE, ALFAJOR, EMPANADA INDIVIDUAL, ...</td>\n",
       "      <td>[ALFAJOR, EMPANADA INDIVIDUAL, FRUTOS SECOS]</td>\n",
       "      <td>GALLETA DULCE</td>\n",
       "      <td>[BARQUILLO, BOLLERIA, CALUGA, GALLETA SALADA, ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7013</th>\n",
       "      <td>2021-04-30</td>\n",
       "      <td>457953</td>\n",
       "      <td>1528614</td>\n",
       "      <td>[PANADERIA, SALAME, QUESO LAMINADO]</td>\n",
       "      <td>[SALAME, PANADERIA]</td>\n",
       "      <td>QUESO LAMINADO</td>\n",
       "      <td>[BOLLERIA, FRUTOS SECOS, JAMON, QUESO LAMINADO]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7014</th>\n",
       "      <td>2021-04-30</td>\n",
       "      <td>457961</td>\n",
       "      <td>1477438</td>\n",
       "      <td>[PANADERIA, GALLETA SALADA, MANTEQUILLA]</td>\n",
       "      <td>[MANTEQUILLA, PANADERIA]</td>\n",
       "      <td>GALLETA SALADA</td>\n",
       "      <td>[BOLLERIA, JAMON, POSTRE INDIVIDUAL, QUESO LAM...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7015</th>\n",
       "      <td>2021-04-30</td>\n",
       "      <td>457970</td>\n",
       "      <td>734552</td>\n",
       "      <td>[JAMON, BOLLERIA, EMPANADA INDIVIDUAL, PANADERIA]</td>\n",
       "      <td>[JAMON, EMPANADA INDIVIDUAL, PANADERIA]</td>\n",
       "      <td>BOLLERIA</td>\n",
       "      <td>[BOLLERIA, POSTRE INDIVIDUAL, QUESO, QUESO LAM...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7016 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           fecha  venta_id_crp  usuario_id_crp  \\\n",
       "0     2021-04-01        428056         1925806   \n",
       "1     2021-04-01        428057          771075   \n",
       "2     2021-04-01        428058         1853170   \n",
       "3     2021-04-01        428060         1916418   \n",
       "4     2021-04-01        428068          526798   \n",
       "...          ...           ...             ...   \n",
       "7011  2021-04-30        457941         1396669   \n",
       "7012  2021-04-30        457948          677920   \n",
       "7013  2021-04-30        457953         1528614   \n",
       "7014  2021-04-30        457961         1477438   \n",
       "7015  2021-04-30        457970          734552   \n",
       "\n",
       "                                       canasta_original  \\\n",
       "0                   [POSTRE INDIVIDUAL, SANDWICH, JUGO]   \n",
       "1      [EMPANADITA, BARQUILLO, PANADERIA, MAP, ALFAJOR]   \n",
       "2                         [EMPANADITA, POSTRE FAMILIAR]   \n",
       "3         [POSTRE INDIVIDUAL, PLATO LIVIANO, PANADERIA]   \n",
       "4                        [EMPANADITA, PIZZA, PANADERIA]   \n",
       "...                                                 ...   \n",
       "7011                  [JUGO, QUESO LAMINADO, PANADERIA]   \n",
       "7012  [GALLETA DULCE, ALFAJOR, EMPANADA INDIVIDUAL, ...   \n",
       "7013                [PANADERIA, SALAME, QUESO LAMINADO]   \n",
       "7014           [PANADERIA, GALLETA SALADA, MANTEQUILLA]   \n",
       "7015  [JAMON, BOLLERIA, EMPANADA INDIVIDUAL, PANADERIA]   \n",
       "\n",
       "                                      canasta_test       leave_one  \\\n",
       "0                    [POSTRE INDIVIDUAL, SANDWICH]            JUGO   \n",
       "1      [EMPANADITA, BARQUILLO, ALFAJOR, PANADERIA]             MAP   \n",
       "2                                [POSTRE FAMILIAR]      EMPANADITA   \n",
       "3               [POSTRE INDIVIDUAL, PLATO LIVIANO]       PANADERIA   \n",
       "4                              [EMPANADITA, PIZZA]       PANADERIA   \n",
       "...                                            ...             ...   \n",
       "7011                   [QUESO LAMINADO, PANADERIA]            JUGO   \n",
       "7012  [ALFAJOR, EMPANADA INDIVIDUAL, FRUTOS SECOS]   GALLETA DULCE   \n",
       "7013                           [SALAME, PANADERIA]  QUESO LAMINADO   \n",
       "7014                      [MANTEQUILLA, PANADERIA]  GALLETA SALADA   \n",
       "7015       [JAMON, EMPANADA INDIVIDUAL, PANADERIA]        BOLLERIA   \n",
       "\n",
       "                                          recomendacion    hit  \n",
       "0     [BARQUILLO, EMPANADA INDIVIDUAL, EMPANADITA, G...   True  \n",
       "1     [BOLLERIA, CALUGA, FRUTOS SECOS, MAP, POSTRE I...   True  \n",
       "2     [COCKTAIL CONGELADO, LASAÑA, MAP FAMILIAR, PAN...  False  \n",
       "3     [EMPANADA INDIVIDUAL, EMPANADITA, ENSALADA, GA...   True  \n",
       "4     [BOLLERIA, EMPANADA INDIVIDUAL, PANADERIA, POS...   True  \n",
       "...                                                 ...    ...  \n",
       "7011  [ALFAJOR, BOLLERIA, DIP, FRUTOS SECOS, JAMON, ...   True  \n",
       "7012  [BARQUILLO, BOLLERIA, CALUGA, GALLETA SALADA, ...  False  \n",
       "7013    [BOLLERIA, FRUTOS SECOS, JAMON, QUESO LAMINADO]   True  \n",
       "7014  [BOLLERIA, JAMON, POSTRE INDIVIDUAL, QUESO LAM...  False  \n",
       "7015  [BOLLERIA, POSTRE INDIVIDUAL, QUESO, QUESO LAM...   True  \n",
       "\n",
       "[7016 rows x 8 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparacion_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "73254672-d83e-41aa-949a-7a870760517a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['BARQUILLO', 'EMPANADITA', 'HELADO', 'PANADERIA',\n",
       "       'POSTRE INDIVIDUAL', 'SOPAS'], dtype='<U17')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(lista_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20622609-5d38-4ec3-ac82-b7956d5dde32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
